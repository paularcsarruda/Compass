{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Exercício 1\n"
      ],
      "metadata": {
        "id": "iI1KFBu7KNIQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wzwmPMjDSak"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Inicializa a Spark Session\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Tarefa4\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "df_nomes = spark.read.csv(\"nomes_aleatorios.txt\")\n",
        "\n",
        "df_nomes.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercício 2\n"
      ],
      "metadata": {
        "id": "VmS2OBKXKUrQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Inicializa a Spark Session\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Tarefa4\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "df_nomes = spark.read.text(\"nomes_aleatorios.txt\")\n",
        "\n",
        "df_nomes = df_nomes.withColumnRenamed(\"_c0\", \"Nomes\")\n",
        "\n",
        "df_nomes.printSchema()\n",
        "df_nomes.show(10)"
      ],
      "metadata": {
        "id": "W2ytYkGUKcns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercício 3"
      ],
      "metadata": {
        "id": "rNddzrXCMSCm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import when, rand\n",
        "\n",
        "# Inicializa a Spark Session\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Tarefa4\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "df_nomes = spark.read.csv(\"nomes_aleatorios.txt\")\n",
        "\n",
        "df_nomes = df_nomes.withColumnRenamed(\"_c0\", \"Nomes\")\n",
        "\n",
        "df_nomes_com_escolaridade = df_nomes.withColumn(\"Escolaridade\",\n",
        "                         when(rand() < 0.33, \"Fundamental\")\n",
        "                        .when(rand() < 0.66, \"Médio\")\n",
        "                        .otherwise(\"Superior\"))\n",
        "\n",
        "df_nomes_com_escolaridade.show(10, False)\n"
      ],
      "metadata": {
        "id": "kSuuG7u3MRlw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercício 4"
      ],
      "metadata": {
        "id": "JzqJ0PW5M-pJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import rand, when\n",
        "\n",
        "# Inicializa a Spark Session\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Tarefa4\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "paises_america_sul = [\"Brasil\", \"Argentina\", \"Colômbia\", \"Venezuela\", \"Peru\",\n",
        "                      \"Chile\", \"Equador\", \"Bolívia\", \"Paraguai\", \"Uruguai\",\n",
        "                      \"Guiana\", \"Suriname\", \"Guiana Francesa\"]\n",
        "\n",
        "df_nomes_com_pais = df_nomes.withColumn(\"Pais\", when(rand() < (1/13), paises_america_sul[0])\n",
        "                                                .when(rand() < (2/13), paises_america_sul[1])\n",
        "                                                .when(rand() < (3/13), paises_america_sul[2])\n",
        "                                                .when(rand() < (4/13), paises_america_sul[3])\n",
        "                                                .when(rand() < (5/13), paises_america_sul[4])\n",
        "                                                .when(rand() < (6/13), paises_america_sul[5])\n",
        "                                                .when(rand() < (7/13), paises_america_sul[6])\n",
        "                                                .when(rand() < (8/13), paises_america_sul[7])\n",
        "                                                .when(rand() < (9/13), paises_america_sul[8])\n",
        "                                                .when(rand() < (10/13), paises_america_sul[9])\n",
        "                                                .when(rand() < (11/13), paises_america_sul[10])\n",
        "                                                .when(rand() < (12/13), paises_america_sul[11])\n",
        "                                                .otherwise(paises_america_sul[12]))\n",
        "\n",
        "df_nomes_com_pais.show(10, False)"
      ],
      "metadata": {
        "id": "L41VjB5VM93M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercício 5"
      ],
      "metadata": {
        "id": "1Nb0I6poOmFj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import rand, expr\n",
        "\n",
        "# Inicializa a Spark Session\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Tarefa4\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "df_nomes_com_nascimento = df_nomes.withColumn(\"AnoNascimento\", expr(\"cast(rand() * (2010 - 1945 + 1) + 1945 as int)\"))\n",
        "\n",
        "df_nomes_com_nascimento.show(10, False)"
      ],
      "metadata": {
        "id": "IrXyeHNUOl3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercício 6"
      ],
      "metadata": {
        "id": "xHtXyJejPkdv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import rand, expr\n",
        "\n",
        "# Inicializa a Spark Session\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Tarefa4\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "df_nomes = df_nomes_com_nascimento.filter(\"AnoNascimento >= 2000\")\n",
        "\n",
        "df_nomes.show(10, False)"
      ],
      "metadata": {
        "id": "mbvtr-BkPly-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercício 7"
      ],
      "metadata": {
        "id": "dArqFBLCQOWy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import rand, expr\n",
        "\n",
        "# Inicializa a Spark Session\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Tarefa4\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "df_nomes_com_nascimento = spark.range(1000).withColumn(\"AnoNascimento\", expr(\"cast(rand() * (2010 - 1945 + 1) + 1945 as int)\"))\n",
        "\n",
        "df_nomes_com_nascimento.createOrReplaceTempView(\"pessoas\")\n",
        "\n",
        "# Consulta SQL para selecionar as pessoas que nasceram neste século\n",
        "df_select = spark.sql(\"SELECT * FROM pessoas WHERE CAST(SUBSTRING(AnoNascimento, 1, 4) AS INT) >= 2000\")\n",
        "\n",
        "df_select.show(10, False)\n"
      ],
      "metadata": {
        "id": "1y4hpr0mQPwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercício 8"
      ],
      "metadata": {
        "id": "ZtYaYBm-RWgu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Inicializar a Spark Session\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Tarefa4\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "millennials_count = df_nomes \\\n",
        "    .select(\"*\") \\\n",
        "    .filter((col(\"AnoNascimento\") >= 1980) & (col(\"AnoNascimento\") <= 1994)) \\\n",
        "    .count()\n",
        "\n",
        "print(\"Número de pessoas da geração Millennials:\", millennials_count)\n",
        "\n"
      ],
      "metadata": {
        "id": "ReNhtscCRXxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Tarefa4\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "df_nomes_com_nascimento.createOrReplaceTempView(\"pessoas\")\n",
        "\n",
        "# SQL - Millennials\n",
        "query = \"\"\"\n",
        "    SELECT COUNT(*)\n",
        "    FROM pessoas\n",
        "    WHERE AnoNascimento >= 1980 AND AnoNascimento <= 1994\n",
        "\"\"\"\n",
        "\n",
        "millennials_count = spark.sql(query).collect()[0][0]\n",
        "\n",
        "print(\"Número de pessoas da geração Millennials:\", millennials_count)\n"
      ],
      "metadata": {
        "id": "NSn4bWfSSa7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercício 10"
      ],
      "metadata": {
        "id": "HHvHTf61TkdA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "------------------------"
      ],
      "metadata": {
        "id": "Kv3Yq37_Z8hf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Inicializa a Spark Session\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Tarefa4\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "df_nomes_com_pais.createOrReplaceTempView(\"Pais\")\n",
        "\n",
        "df_nomes_com_nascimento.createOrReplaceTempView(\"AnoNascimento\")\n",
        "\n",
        "# SQL - pessoas de cada país para cada geração\n",
        "query = \"\"\"\n",
        "    SELECT pessoas_pais.Pais,\n",
        "           CASE WHEN pessoas_nascimento.AnoNascimento BETWEEN 1944 AND 1964 THEN 'Baby Boomers'\n",
        "                WHEN pessoas_nascimento.AnoNascimento BETWEEN 1965 AND 1979 THEN 'Geração X'\n",
        "                WHEN pessoas_nascimento.AnoNascimento BETWEEN 1980 AND 1994 THEN 'Millennials'\n",
        "                WHEN pessoas_nascimento.AnoNascimento BETWEEN 1995 AND 2015 THEN 'Geração Z'\n",
        "                ELSE 'Outra' END AS Geracao,\n",
        "           COUNT(*) AS Quantidade\n",
        "    FROM pessoas_pais\n",
        "    JOIN pessoas_nascimento\n",
        "    ON pessoas_pais.id = pessoas_nascimento.id\n",
        "    GROUP BY pessoas_pais.Pais, Geracao\n",
        "\"\"\"\n",
        "\n",
        "df_resultado = spark.sql(query)\n",
        "\n",
        "df_resultado.orderBy(\"Pais\", \"Geracao\", \"Quantidade\").show(df_resultado.count(), False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ui60ER3NZ8Qr",
        "outputId": "fd51e222-1ef4-4c59-b860-b5ee14f37ced"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------------+----------+\n",
            "|Pais     |Geracao     |Quantidade|\n",
            "+---------+------------+----------+\n",
            "|Argentina|Baby Boomers|10        |\n",
            "|Argentina|Geração X   |5         |\n",
            "|Argentina|Geração Z   |7         |\n",
            "|Argentina|Millennials |8         |\n",
            "|Bolívia  |Geração X   |3         |\n",
            "|Bolívia  |Geração Z   |1         |\n",
            "|Brasil   |Baby Boomers|4         |\n",
            "|Brasil   |Geração X   |1         |\n",
            "|Brasil   |Geração Z   |2         |\n",
            "|Brasil   |Millennials |6         |\n",
            "|Chile    |Baby Boomers|5         |\n",
            "|Chile    |Geração X   |6         |\n",
            "|Chile    |Geração Z   |2         |\n",
            "|Chile    |Millennials |3         |\n",
            "|Colômbia |Baby Boomers|8         |\n",
            "|Colômbia |Geração X   |5         |\n",
            "|Colômbia |Geração Z   |5         |\n",
            "|Colômbia |Millennials |9         |\n",
            "|Equador  |Baby Boomers|3         |\n",
            "|Equador  |Geração Z   |3         |\n",
            "|Equador  |Millennials |7         |\n",
            "|Guiana   |Geração Z   |1         |\n",
            "|Paraguai |Geração Z   |1         |\n",
            "|Peru     |Baby Boomers|6         |\n",
            "|Peru     |Geração X   |5         |\n",
            "|Peru     |Geração Z   |8         |\n",
            "|Peru     |Millennials |5         |\n",
            "|Uruguai  |Millennials |1         |\n",
            "|Venezuela|Baby Boomers|7         |\n",
            "|Venezuela|Geração X   |13        |\n",
            "|Venezuela|Geração Z   |6         |\n",
            "|Venezuela|Millennials |11        |\n",
            "+---------+------------+----------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}