{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Exercício 1\n",
        "--------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "iI1KFBu7KNIQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wzwmPMjDSak",
        "outputId": "dcfd4a42-a443-4a4f-eb6b-dea575a40e34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+\n",
            "|             _c0|\n",
            "+----------------+\n",
            "|  Frances Bennet|\n",
            "|   Jamie Russell|\n",
            "|  Edward Kistler|\n",
            "|   Sheila Maurer|\n",
            "|Donald Golightly|\n",
            "+----------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Inicializa a Spark Session\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Tarefa4\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "df_nomes = spark.read.csv(\"nomes_aleatorios.txt\")\n",
        "\n",
        "df_nomes.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercício 2\n",
        "--------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "VmS2OBKXKUrQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Inicializa a Spark Session\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Tarefa4\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "df_nomes = spark.read.text(\"nomes_aleatorios.txt\")\n",
        "\n",
        "df_nomes = df_nomes.withColumnRenamed(\"_c0\", \"Nomes\")\n",
        "\n",
        "df_nomes.printSchema()\n",
        "df_nomes.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2ytYkGUKcns",
        "outputId": "dcc06d23-7fef-4ee2-829e-9d1eff55b8c0"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- value: string (nullable = true)\n",
            "\n",
            "+-----------------+\n",
            "|            value|\n",
            "+-----------------+\n",
            "|   Frances Bennet|\n",
            "|    Jamie Russell|\n",
            "|   Edward Kistler|\n",
            "|    Sheila Maurer|\n",
            "| Donald Golightly|\n",
            "|       David Gray|\n",
            "|      Joy Bennett|\n",
            "|      Paul Kriese|\n",
            "|Berniece Ornellas|\n",
            "|    Brian Farrell|\n",
            "+-----------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercício 3\n",
        "--------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "rNddzrXCMSCm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import when, rand\n",
        "\n",
        "# Inicializa a Spark Session\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Tarefa4\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "df_nomes = spark.read.csv(\"nomes_aleatorios.txt\")\n",
        "\n",
        "df_nomes = df_nomes.withColumnRenamed(\"_c0\", \"Nomes\")\n",
        "\n",
        "df_nomes_com_escolaridade = df_nomes.withColumn(\"Escolaridade\",\n",
        "                         when(rand() < 0.33, \"Fundamental\")\n",
        "                        .when(rand() < 0.66, \"Médio\")\n",
        "                        .otherwise(\"Superior\"))\n",
        "\n",
        "df_nomes_com_escolaridade.show(10, False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSuuG7u3MRlw",
        "outputId": "2790c18d-31ff-4b16-89db-207e42b165d2"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+------------+\n",
            "|Nomes            |Escolaridade|\n",
            "+-----------------+------------+\n",
            "|Frances Bennet   |Superior    |\n",
            "|Jamie Russell    |Superior    |\n",
            "|Edward Kistler   |Fundamental |\n",
            "|Sheila Maurer    |Fundamental |\n",
            "|Donald Golightly |Fundamental |\n",
            "|David Gray       |Médio       |\n",
            "|Joy Bennett      |Superior    |\n",
            "|Paul Kriese      |Médio       |\n",
            "|Berniece Ornellas|Superior    |\n",
            "|Brian Farrell    |Médio       |\n",
            "+-----------------+------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercício 4\n",
        "--------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "JzqJ0PW5M-pJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import rand, when\n",
        "\n",
        "# Inicializa a Spark Session\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Tarefa4\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "paises_america_sul = [\"Brasil\", \"Argentina\", \"Colômbia\", \"Venezuela\", \"Peru\",\n",
        "                      \"Chile\", \"Equador\", \"Bolívia\", \"Paraguai\", \"Uruguai\",\n",
        "                      \"Guiana\", \"Suriname\", \"Guiana Francesa\"]\n",
        "\n",
        "df_nomes_com_pais = df_nomes.withColumn(\"Pais\", when(rand() < (1/13), paises_america_sul[0])\n",
        "                                                .when(rand() < (2/13), paises_america_sul[1])\n",
        "                                                .when(rand() < (3/13), paises_america_sul[2])\n",
        "                                                .when(rand() < (4/13), paises_america_sul[3])\n",
        "                                                .when(rand() < (5/13), paises_america_sul[4])\n",
        "                                                .when(rand() < (6/13), paises_america_sul[5])\n",
        "                                                .when(rand() < (7/13), paises_america_sul[6])\n",
        "                                                .when(rand() < (8/13), paises_america_sul[7])\n",
        "                                                .when(rand() < (9/13), paises_america_sul[8])\n",
        "                                                .when(rand() < (10/13), paises_america_sul[9])\n",
        "                                                .when(rand() < (11/13), paises_america_sul[10])\n",
        "                                                .when(rand() < (12/13), paises_america_sul[11])\n",
        "                                                .otherwise(paises_america_sul[12]))\n",
        "\n",
        "df_nomes_com_pais.show(10, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L41VjB5VM93M",
        "outputId": "aa1989b5-0f47-452f-cf0f-564b39c53a0c"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+---------+\n",
            "|Nomes            |Pais     |\n",
            "+-----------------+---------+\n",
            "|Frances Bennet   |Chile    |\n",
            "|Jamie Russell    |Brasil   |\n",
            "|Edward Kistler   |Brasil   |\n",
            "|Sheila Maurer    |Brasil   |\n",
            "|Donald Golightly |Peru     |\n",
            "|David Gray       |Bolívia  |\n",
            "|Joy Bennett      |Chile    |\n",
            "|Paul Kriese      |Argentina|\n",
            "|Berniece Ornellas|Peru     |\n",
            "|Brian Farrell    |Argentina|\n",
            "+-----------------+---------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercício 5\n",
        "--------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "1Nb0I6poOmFj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import rand, expr\n",
        "\n",
        "# Inicializa a Spark Session\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Tarefa4\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "df_nomes_com_nascimento = df_nomes.withColumn(\"AnoNascimento\", expr(\"cast(rand() * (2010 - 1945 + 1) + 1945 as int)\"))\n",
        "\n",
        "df_nomes_com_nascimento.show(10, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrXyeHNUOl3L",
        "outputId": "b4b4a8b9-27db-4b1c-a16e-e87d01a7cfd3"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-------------+\n",
            "|Nomes            |AnoNascimento|\n",
            "+-----------------+-------------+\n",
            "|Frances Bennet   |1959         |\n",
            "|Jamie Russell    |1952         |\n",
            "|Edward Kistler   |1974         |\n",
            "|Sheila Maurer    |2008         |\n",
            "|Donald Golightly |1995         |\n",
            "|David Gray       |2003         |\n",
            "|Joy Bennett      |1988         |\n",
            "|Paul Kriese      |1987         |\n",
            "|Berniece Ornellas|1959         |\n",
            "|Brian Farrell    |1975         |\n",
            "+-----------------+-------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercício 6\n",
        "--------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "xHtXyJejPkdv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import rand, expr\n",
        "\n",
        "# Inicializa a Spark Session\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Tarefa4\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "df_nomes = df_nomes_com_nascimento.filter(\"AnoNascimento >= 2000\")\n",
        "\n",
        "df_nomes.show(10, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbvtr-BkPly-",
        "outputId": "8ef424cd-c6a1-4c14-e684-2793b5b4380f"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+-------------+\n",
            "|Nomes          |AnoNascimento|\n",
            "+---------------+-------------+\n",
            "|Sheila Maurer  |2008         |\n",
            "|David Gray     |2003         |\n",
            "|David Medina   |2010         |\n",
            "|Page Marthe    |2007         |\n",
            "|Roxie Bernal   |2001         |\n",
            "|Jessie Jean    |2003         |\n",
            "|Ricky Gilbert  |2004         |\n",
            "|Ana Baker      |2003         |\n",
            "|Jerry Remick   |2010         |\n",
            "|Suzanne Bullard|2006         |\n",
            "+---------------+-------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercício 7\n",
        "--------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "dArqFBLCQOWy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import rand, expr\n",
        "\n",
        "# Inicializa a Spark Session\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Tarefa4\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "df_nomes_com_nascimento = spark.range(1000).withColumn(\"AnoNascimento\", expr(\"cast(rand() * (2010 - 1945 + 1) + 1945 as int)\"))\n",
        "\n",
        "df_nomes_com_nascimento.createOrReplaceTempView(\"pessoas\")\n",
        "\n",
        "# Consulta SQL para selecionar as pessoas que nasceram neste século\n",
        "df_select = spark.sql(\"SELECT * FROM pessoas WHERE CAST(SUBSTRING(AnoNascimento, 1, 4) AS INT) >= 2000\")\n",
        "\n",
        "df_select.show(10, False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1y4hpr0mQPwn",
        "outputId": "f00f1696-c461-4aaf-c132-3a3c9b028dd0"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------------+\n",
            "|id |AnoNascimento|\n",
            "+---+-------------+\n",
            "|2  |2010         |\n",
            "|5  |2002         |\n",
            "|9  |2000         |\n",
            "|10 |2005         |\n",
            "|13 |2000         |\n",
            "|16 |2007         |\n",
            "|17 |2005         |\n",
            "|21 |2001         |\n",
            "|23 |2000         |\n",
            "|42 |2006         |\n",
            "+---+-------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercício 8\n",
        "--------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "ZtYaYBm-RWgu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Inicializar a Spark Session\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Tarefa4\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "millennials_count = df_nomes \\\n",
        "    .select(\"*\") \\\n",
        "    .filter((col(\"AnoNascimento\") >= 1980) & (col(\"AnoNascimento\") <= 1994)) \\\n",
        "    .count()\n",
        "\n",
        "print(\"Número de pessoas da geração Millennials:\", millennials_count)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ReNhtscCRXxc",
        "outputId": "fe473d02-e34b-44d1-e1d3-2e3afefc81ad"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de pessoas da geração Millennials: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercício 9\n",
        "--------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "UMJ2wDXmcktm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Tarefa4\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "df_nomes_com_nascimento.createOrReplaceTempView(\"pessoas\")\n",
        "\n",
        "# SQL - Millennials\n",
        "query = \"\"\"\n",
        "    SELECT COUNT(*)\n",
        "    FROM pessoas\n",
        "    WHERE AnoNascimento >= 1980 AND AnoNascimento <= 1994\n",
        "\"\"\"\n",
        "\n",
        "millennials_count = spark.sql(query).collect()[0][0]\n",
        "\n",
        "print(\"Número de pessoas da geração Millennials:\", millennials_count)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSn4bWfSSa7J",
        "outputId": "a59a5750-7165-4c59-b9a7-bbdb90c450eb"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de pessoas da geração Millennials: 221\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercício 10\n",
        "--------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "HHvHTf61TkdA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Inicializa a Spark Session\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Tarefa4\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "df_nomes_com_pais.createOrReplaceTempView(\"Pais\")\n",
        "\n",
        "df_nomes_com_nascimento.createOrReplaceTempView(\"AnoNascimento\")\n",
        "\n",
        "# SQL - pessoas de cada país para cada geração\n",
        "query = \"\"\"\n",
        "    SELECT pessoas_pais.Pais,\n",
        "           CASE WHEN pessoas_nascimento.AnoNascimento BETWEEN 1944 AND 1964 THEN 'Baby Boomers'\n",
        "                WHEN pessoas_nascimento.AnoNascimento BETWEEN 1965 AND 1979 THEN 'Geração X'\n",
        "                WHEN pessoas_nascimento.AnoNascimento BETWEEN 1980 AND 1994 THEN 'Millennials'\n",
        "                WHEN pessoas_nascimento.AnoNascimento BETWEEN 1995 AND 2015 THEN 'Geração Z'\n",
        "                ELSE 'Outra' END AS Geracao,\n",
        "           COUNT(*) AS Quantidade\n",
        "    FROM pessoas_pais\n",
        "    JOIN pessoas_nascimento\n",
        "    ON pessoas_pais.id = pessoas_nascimento.id\n",
        "    GROUP BY pessoas_pais.Pais, Geracao\n",
        "\"\"\"\n",
        "\n",
        "df_resultado = spark.sql(query)\n",
        "\n",
        "df_resultado.orderBy(\"Pais\", \"Geracao\", \"Quantidade\").show(df_resultado.count(), False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ui60ER3NZ8Qr",
        "outputId": "fd51e222-1ef4-4c59-b860-b5ee14f37ced"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------------+----------+\n",
            "|Pais     |Geracao     |Quantidade|\n",
            "+---------+------------+----------+\n",
            "|Argentina|Baby Boomers|10        |\n",
            "|Argentina|Geração X   |5         |\n",
            "|Argentina|Geração Z   |7         |\n",
            "|Argentina|Millennials |8         |\n",
            "|Bolívia  |Geração X   |3         |\n",
            "|Bolívia  |Geração Z   |1         |\n",
            "|Brasil   |Baby Boomers|4         |\n",
            "|Brasil   |Geração X   |1         |\n",
            "|Brasil   |Geração Z   |2         |\n",
            "|Brasil   |Millennials |6         |\n",
            "|Chile    |Baby Boomers|5         |\n",
            "|Chile    |Geração X   |6         |\n",
            "|Chile    |Geração Z   |2         |\n",
            "|Chile    |Millennials |3         |\n",
            "|Colômbia |Baby Boomers|8         |\n",
            "|Colômbia |Geração X   |5         |\n",
            "|Colômbia |Geração Z   |5         |\n",
            "|Colômbia |Millennials |9         |\n",
            "|Equador  |Baby Boomers|3         |\n",
            "|Equador  |Geração Z   |3         |\n",
            "|Equador  |Millennials |7         |\n",
            "|Guiana   |Geração Z   |1         |\n",
            "|Paraguai |Geração Z   |1         |\n",
            "|Peru     |Baby Boomers|6         |\n",
            "|Peru     |Geração X   |5         |\n",
            "|Peru     |Geração Z   |8         |\n",
            "|Peru     |Millennials |5         |\n",
            "|Uruguai  |Millennials |1         |\n",
            "|Venezuela|Baby Boomers|7         |\n",
            "|Venezuela|Geração X   |13        |\n",
            "|Venezuela|Geração Z   |6         |\n",
            "|Venezuela|Millennials |11        |\n",
            "+---------+------------+----------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}